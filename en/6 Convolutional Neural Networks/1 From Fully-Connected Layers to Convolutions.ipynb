{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fixed-north",
   "metadata": {},
   "source": [
    "# From Fully-Connected Layers to Convolutions\n",
    "\n",
    "Convolutional neural networks (CNNs) are one creative way\n",
    "that machine learning has embraced for exploiting\n",
    "some of the known structure in natural images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-sodium",
   "metadata": {},
   "source": [
    "## Invariance\n",
    "\n",
    "CNNs systematize this idea of *spatial invariance*,\n",
    "exploiting it to learn useful representations\n",
    "with fewer parameters.\n",
    "\n",
    "We can now make these intuitions more concrete\n",
    "by enumerating a few desiderata to guide our design\n",
    "of a neural network architecture suitable for computer vision:\n",
    "\n",
    "1. In the earliest layers, our network\n",
    "    should respond similarly to the same patch,\n",
    "    regardless of where it appears in the image. This principle is called *translation invariance*.\n",
    "1. The earliest layers of the network should focus on local regions,\n",
    "   without regard for the contents of the image in distant regions. This is the *locality* principle.\n",
    "   Eventually, these local representations can be aggregated\n",
    "   to make predictions at the whole image level.\n",
    "\n",
    "Let us see how this translates into mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-mercury",
   "metadata": {},
   "source": [
    "## Constraining the MLP\n",
    "\n",
    "To start off, we can consider an MLP\n",
    "with two-dimensional images $\\mathbf{X}$ as inputs\n",
    "and their immediate hidden representations\n",
    "$\\mathbf{H}$ similarly represented as matrices in mathematics and as two-dimensional tensors in code, where both $\\mathbf{X}$ and $\\mathbf{H}$ have the same shape.\n",
    "Let that sink in.\n",
    "We now conceive of not only the inputs but\n",
    "also the hidden representations as possessing spatial structure.\n",
    "\n",
    "Let $[\\mathbf{X}]_{i, j}$ and $[\\mathbf{H}]_{i, j}$ denote the pixel\n",
    "at location ($i$, $j$)\n",
    "in the input image and hidden representation, respectively.\n",
    "Consequently, to have each of the hidden units\n",
    "receive input from each of the input pixels,\n",
    "we would switch from using weight matrices\n",
    "(as we did previously in MLPs)\n",
    "to representing our parameters\n",
    "as fourth-order weight tensors $\\mathsf{W}$.\n",
    "Suppose that $\\mathbf{U}$ contains biases,\n",
    "we could formally express the fully-connected layer as\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned},$$\n",
    "\n",
    "where the switch from $\\mathsf{W}$ to $\\mathsf{V}$ is entirely cosmetic for now\n",
    "since there is a one-to-one correspondence\n",
    "between coefficients in both fourth-order tensors.\n",
    "We simply re-index the subscripts $(k, l)$\n",
    "such that $k = i+a$ and $l = j+b$.\n",
    "In other words, we set $[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$.\n",
    "The indices $a$ and $b$ run over both positive and negative offsets,\n",
    "covering the entire image.\n",
    "For any given location ($i$, $j$) in the hidden representation $[\\mathbf{H}]_{i, j}$,\n",
    "we compute its value by summing over pixels in $x$,\n",
    "centered around $(i, j)$ and weighted by $[\\mathsf{V}]_{i, j, a, b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-institute",
   "metadata": {},
   "source": [
    "### Translation Invariance\n",
    "\n",
    "Now let us invoke the first principle\n",
    "established above: translation invariance.\n",
    "This implies that a shift in the input $\\mathbf{X}$\n",
    "should simply lead to a shift in the hidden representation $\\mathbf{H}$.\n",
    "This is only possible if $\\mathsf{V}$ and $\\mathbf{U}$ do not actually depend on $(i, j)$,\n",
    "i.e., we have $[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$ and $\\mathbf{U}$ is a constant, say $u$.\n",
    "As a result, we can simplify the definition for $\\mathbf{H}$:\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "\n",
    "This is a *convolution*!\n",
    "We are effectively weighting pixels at $(i+a, j+b)$\n",
    "in the vicinity of location $(i, j)$ with coefficients $[\\mathbf{V}]_{a, b}$\n",
    "to obtain the value $[\\mathbf{H}]_{i, j}$.\n",
    "Note that $[\\mathbf{V}]_{a, b}$ needs many fewer coefficients than $[\\mathsf{V}]_{i, j, a, b}$ since it\n",
    "no longer depends on the location within the image.\n",
    "We have made significant progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-prompt",
   "metadata": {},
   "source": [
    "###  Locality\n",
    "\n",
    "Now let us invoke the second principle: locality.\n",
    "As motivated above, we believe that we should not have\n",
    "to look very far away from location $(i, j)$\n",
    "in order to glean relevant information\n",
    "to assess what is going on at $[\\mathbf{H}]_{i, j}$.\n",
    "This means that outside some range $|a|> \\Delta$ or $|b| > \\Delta$,\n",
    "we should set $[\\mathbf{V}]_{a, b} = 0$.\n",
    "Equivalently, we can rewrite $[\\mathbf{H}]_{i, j}$ as\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    ":eqlabel:`eq_conv-layer`\n",
    "\n",
    "Note that, in a nutshell, is a *convolutional layer*.\n",
    "*Convolutional neural networks* (CNNs)\n",
    "are a special family of neural networks that contain convolutional layers.\n",
    "In the deep learning research community,\n",
    "$\\mathbf{V}$ is referred to as a *convolution kernel*,\n",
    "a *filter*, or simply the layer's *weights* that are often learnable parameters.\n",
    "When the local region is small,\n",
    "the difference as compared with a fully-connected network can be dramatic.\n",
    "While previously, we might have required billions of parameters\n",
    "to represent just a single layer in an image-processing network,\n",
    "we now typically need just a few hundred, without\n",
    "altering the dimensionality of either\n",
    "the inputs or the hidden representations.\n",
    "The price paid for this drastic reduction in parameters\n",
    "is that our features are now translation invariant\n",
    "and that our layer can only incorporate local information,\n",
    "when determining the value of each hidden activation.\n",
    "All learning depends on imposing inductive bias.\n",
    "When that bias agrees with reality,\n",
    "we get sample-efficient models\n",
    "that generalize well to unseen data.\n",
    "But of course, if those biases do not agree with reality,\n",
    "e.g., if images turned out not to be translation invariant,\n",
    "our models might struggle even to fit our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-diversity",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "\n",
    "Before going further, we should briefly review\n",
    "why the above operation is called a convolution.\n",
    "In mathematics, the *convolution* between two functions,\n",
    "say $f, g: \\mathbb{R}^d \\to \\mathbb{R}$ is defined as\n",
    "\n",
    "$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n",
    "\n",
    "That is, we measure the overlap between $f$ and $g$\n",
    "when one function is \"flipped\" and shifted by $\\mathbf{x}$.\n",
    "Whenever we have discrete objects, the integral turns into a sum.\n",
    "For instance, for vectors from\n",
    "the set of square summable infinite dimensional vectors\n",
    "with index running over $\\mathbb{Z}$ we obtain the following definition:\n",
    "\n",
    "$$(f * g)(i) = \\sum_a f(a) g(i-a).$$\n",
    "\n",
    "For two-dimensional tensors, we have a corresponding sum\n",
    "with indices $(a, b)$ for $f$ and $(i-a, j-b)$ for $g$, respectively:\n",
    "\n",
    "$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$$\n",
    ":eqlabel:`eq_2d-conv-discrete`\n",
    "\n",
    "This looks similar to :eqref:`eq_conv-layer`, with one major difference.\n",
    "Rather than using $(i+a, j+b)$, we are using the difference instead.\n",
    "Note, though, that this distinction is mostly cosmetic\n",
    "since we can always match the notation between\n",
    ":eqref:`eq_conv-layer` and :eqref:`eq_2d-conv-discrete`.\n",
    "Our original definition in :eqref:`eq_conv-layer` more properly\n",
    "describes a *cross-correlation*.\n",
    "We will come back to this in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-simon",
   "metadata": {},
   "source": [
    "## \"Where's Waldo\" Revisited\n",
    "\n",
    "Returning to our Waldo detector, let us see what this looks like.\n",
    "The convolutional layer picks windows of a given size\n",
    "and weighs intensities according to the filter $\\mathsf{V}$, as demonstrated in figure.\n",
    "We might aim to learn a model so that\n",
    "wherever the \"waldoness\" is highest,\n",
    "we should find a peak in the hidden layer representations.\n",
    "\n",
    "![Detect Waldo.](../img/waldo-mask.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-sixth",
   "metadata": {},
   "source": [
    "### Channels\n",
    "\n",
    "There is just one problem with this approach.\n",
    "So far, we blissfully ignored that images consist\n",
    "of 3 channels: red, green, and blue.\n",
    "In reality, images are not two-dimensional objects\n",
    "but rather third-order tensors,\n",
    "characterized by a height, width, and channel,\n",
    "e.g., with shape $1024 \\times 1024 \\times 3$ pixels.\n",
    "While the first two of these axes concern spatial relationships,\n",
    "the third can be regarded as assigning\n",
    "a multidimensional representation to each pixel location.\n",
    "We thus index $\\mathsf{X}$ as $[\\mathsf{X}]_{i, j, k}$.\n",
    "The convolutional filter has to adapt accordingly.\n",
    "Instead of $[\\mathbf{V}]_{a,b}$, we now have $[\\mathsf{V}]_{a,b,c}$.\n",
    "\n",
    "Moreover, just as our input consists of a third-order tensor,\n",
    "it turns out to be a good idea to similarly formulate\n",
    "our hidden representations as third-order tensors $\\mathsf{H}$.\n",
    "In other words, rather than just having a single hidden representation\n",
    "corresponding to each spatial location,\n",
    "we want an entire vector of hidden representations\n",
    "corresponding to each spatial location.\n",
    "We could think of the hidden representations as comprising\n",
    "a number of two-dimensional grids stacked on top of each other.\n",
    "As in the inputs, these are sometimes called *channels*.\n",
    "They are also sometimes called *feature maps*,\n",
    "as each provides a spatialized set\n",
    "of learned features to the subsequent layer.\n",
    "Intuitively, you might imagine that at lower layers that are closer to inputs,\n",
    "some channels could become specialized to recognize edges while\n",
    "others could recognize textures.\n",
    "\n",
    "\n",
    "To support multiple channels in both inputs ($\\mathsf{X}$) and hidden representations ($\\mathsf{H}$),\n",
    "we can add a fourth coordinate to $\\mathsf{V}$: $[\\mathsf{V}]_{a, b, c, d}$.\n",
    "Putting everything together we have:\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",
    ":eqlabel:`eq_conv-layer-channels`\n",
    "\n",
    "where $d$ indexes the output channels in the hidden representations $\\mathsf{H}$. The subsequent convolutional layer will go on to take a third-order tensor, $\\mathsf{H}$, as the input.\n",
    "Being more general,\n",
    ":eqref:`eq_conv-layer-channels` is\n",
    "the definition of a convolutional layer for multiple channels, where $\\mathsf{V}$ is a kernel or filter of the layer.\n",
    "\n",
    "There are still many operations that we need to address.\n",
    "For instance, we need to figure out how to combine all the hidden representations\n",
    "to a single output, e.g., whether there is a Waldo *anywhere* in the image.\n",
    "We also need to decide how to compute things efficiently,\n",
    "how to combine multiple layers,\n",
    "appropriate activation functions,\n",
    "and how to make reasonable design choices\n",
    "to yield networks that are effective in practice.\n",
    "We turn to these issues in the remainder of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-russell",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Translation invariance in images implies that all patches of an image will be treated in the same manner.\n",
    "* Locality means that only a small neighborhood of pixels will be used to compute the corresponding hidden representations.\n",
    "* In image processing, convolutional layers typically require many fewer parameters than fully-connected layers.\n",
    "* CNNS are a special family of neural networks that contain convolutional layers.\n",
    "* Channels on input and output allow our model to capture multiple aspects of an image  at each spatial location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-mattress",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Assume that the size of the convolution kernel is $\\Delta = 0$.\n",
    "   Show that in this case the convolution kernel\n",
    "   implements an MLP independently for each set of channels.\n",
    "1. Why might translation invariance not be a good idea after all?\n",
    "1. What problems must we deal with when deciding how\n",
    "   to treat hidden representations corresponding to pixel locations\n",
    "   at the boundary of an image?\n",
    "1. Describe an analogous convolutional layer for audio.\n",
    "1. Do you think that convolutional layers might also be applicable for text data?\n",
    "   Why or why not?\n",
    "1. Prove that $f * g = g * f$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
