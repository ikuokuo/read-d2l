{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "healthy-resource",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "Often, as we process images, we want to gradually reduce the spatial resolution of our hidden representations, aggregating information so that the higher up we go in the network, the larger the receptive field (in the input) to which each hidden node is sensitive.\n",
    "\n",
    "Often our ultimate task asks some global question about the image, e.g., does it contain a cat? So typically the units of our final layer should be sensitive to the entire input. By gradually aggregating information, yielding coarser and coarser maps, we accomplish this goal of ultimately learning a global representation, while keeping all of the advantages of convolutional layers at the intermediate layers of processing.\n",
    "\n",
    "Moreover, when detecting lower-level features, such as edges\n",
    "(as discussed in :numref:`sec_conv_layer`),\n",
    "we often want our representations to be somewhat invariant to translation.\n",
    "For instance, if we take the image `X`\n",
    "with a sharp delineation between black and white\n",
    "and shift the whole image by one pixel to the right,\n",
    "i.e., `Z[i, j] = X[i, j + 1]`,\n",
    "then the output for the new image `Z` might be vastly different.\n",
    "The edge will have shifted by one pixel.\n",
    "In reality, objects hardly ever occur exactly at the same place.\n",
    "In fact, even with a tripod and a stationary object,\n",
    "vibration of the camera due to the movement of the shutter\n",
    "might shift everything by a pixel or so\n",
    "(high-end cameras are loaded with special features to address this problem).\n",
    "\n",
    "This section introduces *pooling layers*,\n",
    "which serve the dual purposes of\n",
    "mitigating the sensitivity of convolutional layers to location\n",
    "and of spatially downsampling representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-expense",
   "metadata": {},
   "source": [
    "## Maximum Pooling and Average Pooling\n",
    "\n",
    "Like convolutional layers, *pooling* operators\n",
    "consist of a fixed-shape window that is slid over\n",
    "all regions in the input according to its stride,\n",
    "computing a single output for each location traversed\n",
    "by the fixed-shape window (sometimes known as the *pooling window*).\n",
    "However, unlike the cross-correlation computation\n",
    "of the inputs and kernels in the convolutional layer,\n",
    "the pooling layer contains no parameters (there is no *kernel*).\n",
    "Instead, pooling operators are deterministic,\n",
    "typically calculating either the maximum or the average value\n",
    "of the elements in the pooling window.\n",
    "These operations are called *maximum pooling* (*max pooling* for short)\n",
    "and *average pooling*, respectively.\n",
    "\n",
    "![](../img/pooling.svg) Maximum pooling with a pooling window shape of $2\\times 2$. The shaded portions are the first output element as well as the input tensor elements used for the output computation: $\\max(0, 1, 3, 4)=4$.\n",
    "\n",
    "A pooling layer with a pooling window shape of $p \\times q$\n",
    "is called a $p \\times q$ pooling layer.\n",
    "The pooling operation is called $p \\times q$ pooling.\n",
    "\n",
    "Let us return to the object edge detection example\n",
    "mentioned at the beginning of this section.\n",
    "Now we will use the output of the convolutional layer\n",
    "as the input for $2\\times 2$ maximum pooling.\n",
    "Set the convolutional layer input as `X` and the pooling layer output as `Y`. Whether or not the values of `X[i, j]` and `X[i, j + 1]` are different,\n",
    "or `X[i, j + 1]` and `X[i, j + 2]` are different,\n",
    "the pooling layer always outputs `Y[i, j] = 1`.\n",
    "That is to say, using the $2\\times 2$ maximum pooling layer,\n",
    "we can still detect if the pattern recognized by the convolutional layer\n",
    "moves no more than one element in height or width.\n",
    "\n",
    "In the code below, we implement the forward propagation\n",
    "of the pooling layer in the `pool2d` function.\n",
    "This function is similar to the `corr2d` function.\n",
    "However, here we have no kernel, computing the output\n",
    "as either the maximum or the average of each region in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspended-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-chicago",
   "metadata": {},
   "source": [
    "## Padding and Stride\n",
    "\n",
    "As with convolutional layers, pooling layers\n",
    "can also change the output shape.\n",
    "And as before, we can alter the operation to achieve a desired output shape\n",
    "by padding the input and adjusting the stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gorgeous-mobility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-burden",
   "metadata": {},
   "source": [
    "By default, the stride and the pooling window in the instance from the framework's built-in class\n",
    "have the same shape.\n",
    "Below, we use a pooling window of shape `(3, 3)`,\n",
    "so we get a stride shape of `(3, 3)` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brief-knight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-alliance",
   "metadata": {},
   "source": [
    "The stride and padding can be manually specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "permanent-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-italy",
   "metadata": {},
   "source": [
    "Of course, we can specify an arbitrary rectangular pooling window\n",
    "and specify the padding and stride for height and width, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "furnished-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), padding=(1, 1), stride=(2, 3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-louisville",
   "metadata": {},
   "source": [
    "## Multiple Channels\n",
    "\n",
    "When processing multi-channel input data,\n",
    "the pooling layer pools each input channel separately,\n",
    "rather than summing the inputs up over channels\n",
    "as in a convolutional layer.\n",
    "This means that the number of output channels for the pooling layer\n",
    "is the same as the number of input channels.\n",
    "Below, we will concatenate tensors `X` and `X + 1`\n",
    "on the channel dimension to construct an input with 2 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "configured-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-photograph",
   "metadata": {},
   "source": [
    "As we can see, the number of output channels is still 2 after pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "french-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-share",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Taking the input elements in the pooling window, the maximum pooling operation assigns the maximum value as the output and the average pooling operation assigns the average value as the output.\n",
    "* One of the major benefits of a pooling layer is to alleviate the excessive sensitivity of the convolutional layer to location.\n",
    "* We can specify the padding and stride for the pooling layer.\n",
    "* Maximum pooling, combined with a stride larger than 1 can be used to reduce the spatial dimensions (e.g., width and height).\n",
    "* The pooling layer's number of output channels is the same as the number of input channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-freedom",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Can you implement average pooling as a special case of a convolution layer? If so, do it.\n",
    "1. Can you implement max pooling as a special case of a convolution layer? If so, do it.\n",
    "1. What is the computational cost of the pooling layer? Assume that the input to the pooling layer is of size $c\\times h\\times w$, the pooling window has a shape of $p_h\\times p_w$ with a padding of $(p_h, p_w)$ and a stride of $(s_h, s_w)$.\n",
    "1. Why do you expect maximum pooling and average pooling to work differently?\n",
    "1. Do we need a separate minimum pooling layer? Can you replace it with another operation?\n",
    "1. Is there another operation between average and maximum pooling that you could consider (hint: recall the softmax)? Why might it not be so popular?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
