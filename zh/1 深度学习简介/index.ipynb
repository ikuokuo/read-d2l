{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习简介\n",
    "\n",
    "## 概念\n",
    "\n",
    "通俗来说，机器学习是一⻔讨论各式各样的适用于不同问题的函数形式，以及如何使用数据来有效地获取函数参数具体值的学科。深度学习是指机器学习中的一类函数，它们的形式通常为多层神经网络。\n",
    "\n",
    "## 起源\n",
    "\n",
    "- 思想：神经网络模型、数据编程\n",
    "- 本质：数据分析\n",
    "- 工具：概率论、统计学、模式识别等\n",
    "\n",
    "1. 统计学\n",
    "  - 现代统计学在20世纪的真正起⻜要归功于数据的收集和发布。\n",
    "2. 神经科学与心理学\n",
    "  - 赫布理论：神经是通过正向强化来学习的。\n",
    "    - 是感知机学习算法的原型，并成为支撑今日深度学习的随机梯度下降算法的基石：强化合意的行为、惩罚不合意的行为，最终获得优良的神经网络参数。\n",
    "  - 神经网络，源于生物学的灵感。时至今日，绝大多数都包含以下的核心原则：\n",
    "    - 交替使用线性处理单元与非线性处理单元，它们经常被称为“层”\n",
    "    - 使用链式法则（即反向传播）来更新网络的参数\n",
    "\n",
    "## 发展\n",
    "\n",
    "- 数据 ↑\n",
    "- 算力 ↑\n",
    "\n",
    "这也相应导致了机器学习和统计学的最优选择从广义线性模型及核方法变化为深度多层神经网络。这样的变化正是诸如多层感知机、卷积神经网络、⻓短期记忆循环神经网络和Q学习等深度学习的支柱模型在过去10年从坐了数十年的冷板凳上站起来被“重新发现”的原因。\n",
    "\n",
    "下面的列表仅仅涵盖了近十年来深度学习⻓足发展的部分原因。\n",
    "\n",
    "- 优秀的容量控制方法，如丢弃法，使大型网络的训练不再受制于过拟合（大型神经网络学会记忆大部分训练数据的行为）。\n",
    "  - 这是靠在整个网络中注入噪声而达到的，如训练时随机将权重替换为随机的数字。\n",
    "- 注意力机制解决了另一个困扰统计学超过一个世纪的问题：如何在不增加参数的情况下扩展一个系统的记忆容量和复杂度。\n",
    "  - 注意力机制使用了一个可学习的指针结构来构建出一个精妙的解决方法。也就是说，与其在像机器翻译这样的任务中记忆整个句子，不如记忆指向翻译的中间状态的指针。由于生成译文前不需要再存储整句原文的信息，这样的结构使准确翻译⻓句变得可能。\n",
    "- 记忆网络和神经编码器—解释器这样的多阶设计使得针对推理过程的迭代建模方法变得可能。\n",
    "  - 这些模型允许重复修改深度网络的内部状态，这样就能模拟出推理链条上的各个步骤，就好像处理器在计算过程中修改内存一样。\n",
    "- 另一个重大发展是生成对抗网络的发明。\n",
    "  - 传统上，用在概率分布估计和生成模型上的统计方法更多地关注于找寻正确的概率分布，以及正确的采样算法。生成对抗网络的关键创新在于将采样部分替换成了任意的含有可微分参数的算法。这些参数将被训练到使辨别器不能再分辨真实的和生成的样本。生成对抗网络可使用任意算法来生成输出的这一特性为许多技巧打开了新的大⻔。\n",
    "- 许多情况下单块GPU已经不能满足在大型数据集上进行训练的需要。过去10年内我们构建分布式并行训练算法的能力已经有了极大的提升。\n",
    "  - 设计可扩展算法的最大瓶颈在于深度学习优化算法的核心：随机梯度下降需要相对更小的批量。与此同时，更小的批量也会降低GPU的效率。如果使用1,024块GPU，每块GPU的批量大小为32个样本，那么单步训练的批量大小将是32,000个以上。近年来李沐、Yang You等人以及Xianyan Jia等人的工作将批量大小增至多达64,000个样例，并把在ImageNet数据集上训练ResNet-50模型的时间降到了7分钟。与之相比，最初的训练时间需要以天来计算。\n",
    "- 并行计算的能力也为至少在可以采用模拟情况下的强化学习的发展贡献了力量。\n",
    "  - 并行计算帮助计算机在围棋、雅达利游戏、星际争霸和物理模拟上达到了超过人类的水准。\n",
    "- 深度学习框架也在传播深度学习思想的过程中扮演了重要⻆色。\n",
    "  - Caffe、Torch和Theano这样的第一代框架使建模变得更简单。许多开创性的论文都用到了这些框架。如今它们已经被TensorFlow（经常是以高层API Keras的形式被使用）、CNTK、Caffe 2和Apache MXNet所取代。第三代，即命令式深度学习框架，是由用类似NumPy的语法来定义模型的Chainer所开创的。这样的思想后来被PyTorch和MXNet的Gluon API采用。\n",
    "\n",
    "系统研究者负责构建更好的工具，统计学家建立更好的模型。这样的分工使工作大大简化。\n",
    "\n",
    "## 成功案例\n",
    "\n",
    "- 语音识别\n",
    "- 物体识别\n",
    "- 博弈\n",
    "- 自动驾驶\n",
    "- ...\n",
    "\n",
    "## 特点\n",
    "\n",
    "深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合的函数足够多时，深度学习模型就可以表达非常复杂的变换。\n",
    "\n",
    "深度学习可以逐级表示越来越抽象的概念或模式。作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。\n",
    "\n",
    "1. 端到端的训练\n",
    "  - 也就是说，并不是将单独调试的部分拼凑起来 组成一个系统，而是将整个系统组建好之后一起训练。\n",
    "  - 比如说，计算机视觉科学家之前曾一度将特征抽取与机器学习模型的构建分开处理，像是Canny边缘探测和SIFT特征提取曾占据统治性地位达10年以上，但这也就是人类能找到的最好方法了。当深度学习进入这个领域后，这些特征提取方法就被性能更强的自动优化的逐级过滤器替代了。\n",
    "  - 相似地，在自然语言处理领域，词袋模型多年来都被认为是不二之选。词袋模型是将一个句子映射到一个词频向量的模型，但这样的做法完全忽视了单词的排列顺序或者句中的标点符号。不幸的是，我们也没有能力来手工抽取更好的特征。但是自动化的算法反而可以从所有可能的特征中搜寻最好的那个，这也带来了极大的进步。\n",
    "2. 含参数统计模型转向完全无参数的模型\n",
    "3. 对非最优解的包容、对非凸非线性优化的使用，以及勇于尝试没有被证明过的方法\n",
    "4. 深度学习社区⻓期以来以在学术界和企业之间分享工具而自豪，并开源了许多优秀的软件库、统计模型和预训练网络"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
